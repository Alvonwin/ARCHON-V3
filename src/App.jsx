import { useState, useRef, useEffect, useCallback } from 'react'
import './App.css'
import VoiceInput from './VoiceInput'
import { useWebSocketBridge } from './useWebSocketBridge'
import config from './config'

function App() {
  const [messages, setMessages] = useState(() => {
    // Charger historique au dÃ©marrage
    const saved = localStorage.getItem('archon_messages')
    return saved ? JSON.parse(saved) : []
  })
  const [input, setInput] = useState('')
  const [isLoading, setIsLoading] = useState(false)
  const [handsFreeModeEnabled, setHandsFreeModeEnabled] = useState(true)
  const [systemPrompt, setSystemPrompt] = useState('') // Prompt dynamique
  const [isStarted, setIsStarted] = useState(false) // Pour gÃ©rer autoplay audio
  const [aiMode, setAiMode] = useState('claude') // 'gpt4all' ou 'claude' - DÃ‰FAUT: Claude Code
  const messagesEndRef = useRef(null)
  const voiceInputRef = useRef(null)
  const audioContextRef = useRef(null) // AudioContext global pour TTS
  const audioElementRef = useRef(null) // Audio element rÃ©utilisable pour TTS

  // ğŸŒ‰ WebSocket Bridge - Connexion au Saint Graal
  const handleClaudeResponseFromBridge = useCallback((content, fullMessage) => {
    console.log('ğŸŒ‰ [Bridge] RÃ©ponse de Claude reÃ§ue via WebSocket:', content.substring(0, 100) + '...')

    // Ajouter le message Ã  l'historique
    setMessages(prev => [...prev, {
      role: 'assistant',
      content: content,
      timestamp: new Date().toLocaleTimeString('fr-FR'),
      source: 'websocket-bridge'
    }])

    // Si mode mains libres: vocaliser automatiquement
    if (handsFreeModeEnabled) {
      setTimeout(() => {
        speakText(content)
      }, 500)
    }
  }, [handsFreeModeEnabled])

  const wsBridge = useWebSocketBridge(handleClaudeResponseFromBridge)

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }

  // Charger prompt dynamique au dÃ©marrage
  useEffect(() => {
    const loadSystemPrompt = async () => {
      try {
        const response = await fetch(`${config.BACKEND_URL}/claude-resurrection`)
        const data = await response.json()

        // Extraire section pertinente du CLAUDE_RESURRECTION
        const content = data.content
        setSystemPrompt(content)
        console.log('âœ… Prompt systÃ¨me chargÃ© depuis CLAUDE_RESURRECTION.md')
      } catch (error) {
        console.error('âŒ Erreur chargement prompt:', error)
        // Fallback: prompt minimal
        setSystemPrompt(`Tu es ARCHON, assistant IA local fonctionnant avec Mistral 7B.

Tu travailles avec Alain sur un projet de prÃ©servation de mÃ©moire. Sois concis, proactif et autonome. RÃ©ponds toujours en franÃ§ais avec tutoiement.`)
      }
    }

    loadSystemPrompt()
  }, [])

  // Sauvegarder automatiquement les messages (localStorage + backend)
  useEffect(() => {
    if (messages.length > 0) {
      // localStorage (rapide)
      localStorage.setItem('archon_messages', JSON.stringify(messages))

      // Backend (MÃ©moire V3) - debounced
      const saveToBackend = setTimeout(async () => {
        try {
          await fetch(`${config.BACKEND_URL}/save-memory`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ messages })
          })
          console.log('âœ… SauvegardÃ© en MÃ©moire V3')
        } catch (error) {
          console.log('âš ï¸  Backend sauvegarde non disponible:', error.message)
        }
      }, 3000) // Attendre 3s aprÃ¨s dernier message

      return () => clearTimeout(saveToBackend)
    }
  }, [messages])

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  // DÃ©marrer capture vocale automatiquement en mode mains libres
  useEffect(() => {
    if (handsFreeModeEnabled && voiceInputRef.current && isStarted) {
      // Attendre 2s pour que tout soit chargÃ©
      const timer = setTimeout(() => {
        console.log('ğŸ™ï¸ Mode mains libres: dÃ©marrage auto de la capture')
        voiceInputRef.current?.startRecording()
      }, 2000)
      return () => clearTimeout(timer)
    }
  }, [handsFreeModeEnabled, isStarted])

  const clearHistory = () => {
    if (confirm('Effacer tout l\'historique des conversations ?')) {
      setMessages([])
      localStorage.removeItem('archon_messages')
    }
  }

  const exportHistory = () => {
    const dataStr = JSON.stringify(messages, null, 2)
    const dataBlob = new Blob([dataStr], { type: 'application/json' })
    const url = URL.createObjectURL(dataBlob)
    const link = document.createElement('a')
    link.href = url
    link.download = `archon_conversation_${new Date().toISOString().split('T')[0]}.json`
    link.click()
    URL.revokeObjectURL(url)
  }

  const saveToMemoryV3 = () => {
    // Format markdown pour MÃ©moire V3
    const timestamp = new Date().toISOString()
    const date = timestamp.split('T')[0]

    let markdown = `# Conversation ARCHON V3 - ${date}\n\n`
    markdown += `**Timestamp**: ${timestamp}\n`
    markdown += `**Nombre de messages**: ${messages.length}\n`
    markdown += `**Mode**: Assistant IA Local (Mistral 7B)\n\n`
    markdown += `---\n\n`

    messages.forEach((msg, i) => {
      const role = msg.role === 'user' ? 'ğŸ‘¤ **Alain**' : 'ğŸ¤– **ARCHON**'
      markdown += `### ${role} (${msg.timestamp})\n\n`
      markdown += `${msg.content}\n\n`
      markdown += `---\n\n`
    })

    const blob = new Blob([markdown], { type: 'text/markdown' })
    const url = URL.createObjectURL(blob)
    const link = document.createElement('a')
    link.href = url
    link.download = `archon_${date}_${messages.length}msg.md`
    link.click()
    URL.revokeObjectURL(url)
  }

  const handleVoiceTranscript = (transcript) => {
    // Mode mains libres: envoi direct
    if (handsFreeModeEnabled && transcript.trim()) {
      sendMessageDirect(transcript)
    } else {
      // Mode normal: ajouter au champ input
      setInput(prev => prev ? `${prev} ${transcript}` : transcript)
    }
  }

  // SystÃ¨me de sons de notification
  const playSound = (soundType) => {
    try {
      const audioContext = audioContextRef.current || new (window.AudioContext || window.webkitAudioContext)()
      if (!audioContextRef.current) {
        audioContextRef.current = audioContext
      }

      const oscillator = audioContext.createOscillator()
      const gainNode = audioContext.createGain()

      oscillator.connect(gainNode)
      gainNode.connect(audioContext.destination)

      // DiffÃ©rents sons selon le type
      switch (soundType) {
        case 'recording-start':
          // Son ascendant (do-mi-sol)
          oscillator.frequency.setValueAtTime(523, audioContext.currentTime) // Do
          oscillator.frequency.setValueAtTime(659, audioContext.currentTime + 0.1) // Mi
          oscillator.frequency.setValueAtTime(784, audioContext.currentTime + 0.2) // Sol
          gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
          gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3)
          oscillator.start(audioContext.currentTime)
          oscillator.stop(audioContext.currentTime + 0.3)
          console.log('ğŸ”´ Son: DÃ©but enregistrement')
          break

        case 'recording-stop':
          // Son descendant (sol-mi-do)
          oscillator.frequency.setValueAtTime(784, audioContext.currentTime) // Sol
          oscillator.frequency.setValueAtTime(659, audioContext.currentTime + 0.1) // Mi
          oscillator.frequency.setValueAtTime(523, audioContext.currentTime + 0.2) // Do
          gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
          gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3)
          oscillator.start(audioContext.currentTime)
          oscillator.stop(audioContext.currentTime + 0.3)
          console.log('â¹ï¸ Son: Fin enregistrement')
          break

        case 'message-sent':
          // Bip montant rapide
          oscillator.frequency.setValueAtTime(800, audioContext.currentTime)
          oscillator.frequency.exponentialRampToValueAtTime(1200, audioContext.currentTime + 0.1)
          gainNode.gain.setValueAtTime(0.2, audioContext.currentTime)
          gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.15)
          oscillator.start(audioContext.currentTime)
          oscillator.stop(audioContext.currentTime + 0.15)
          console.log('ğŸ“¤ Son: Message envoyÃ©')
          break

        case 'message-received':
          // Double bip doux
          oscillator.frequency.setValueAtTime(600, audioContext.currentTime)
          oscillator.frequency.setValueAtTime(800, audioContext.currentTime + 0.15)
          gainNode.gain.setValueAtTime(0.25, audioContext.currentTime)
          gainNode.gain.setValueAtTime(0.25, audioContext.currentTime + 0.15)
          gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3)
          oscillator.start(audioContext.currentTime)
          oscillator.stop(audioContext.currentTime + 0.3)
          console.log('ğŸ“¥ Son: Message reÃ§u')
          break

        case 'tts-start':
          // Triple bip rapide
          const osc1 = audioContext.createOscillator()
          const osc2 = audioContext.createOscillator()
          const osc3 = audioContext.createOscillator()
          const gain = audioContext.createGain()

          osc1.connect(gain)
          osc2.connect(gain)
          osc3.connect(gain)
          gain.connect(audioContext.destination)

          osc1.frequency.value = 700
          osc2.frequency.value = 700
          osc3.frequency.value = 700

          gain.gain.setValueAtTime(0.15, audioContext.currentTime)
          gain.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.4)

          osc1.start(audioContext.currentTime)
          osc1.stop(audioContext.currentTime + 0.08)

          osc2.start(audioContext.currentTime + 0.1)
          osc2.stop(audioContext.currentTime + 0.18)

          osc3.start(audioContext.currentTime + 0.2)
          osc3.stop(audioContext.currentTime + 0.28)

          console.log('ğŸ”Š Son: DÃ©but vocalisation')
          return // Skip oscillator cleanup (already stopped)

        case 'error':
          // Son d'erreur (basse frÃ©quence)
          oscillator.frequency.setValueAtTime(200, audioContext.currentTime)
          gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
          gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.4)
          oscillator.start(audioContext.currentTime)
          oscillator.stop(audioContext.currentTime + 0.4)
          console.log('âŒ Son: Erreur')
          break

        default:
          // Son neutre
          oscillator.frequency.value = 440
          gainNode.gain.setValueAtTime(0.2, audioContext.currentTime)
          gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.2)
          oscillator.start(audioContext.currentTime)
          oscillator.stop(audioContext.currentTime + 0.2)
      }
    } catch (error) {
      console.error('âŒ Erreur playSound:', error)
    }
  }

  const speakText = async (text) => {
    console.log('ğŸ”Š speakText appelÃ© avec:', text.substring(0, 50))
    try {
      const response = await fetch(`${config.VOICE_BACKEND_URL}/synthesize`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text })
      })

      console.log('ğŸ“¡ RÃ©ponse TTS:', response.status)

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`)
      }

      const audioBlob = await response.blob()
      console.log('ğŸµ Audio blob reÃ§u, taille:', audioBlob.size)

      // Utiliser l'Ã©lÃ©ment audio rÃ©utilisable
      const audio = audioElementRef.current
      if (!audio) {
        console.error('âŒ Audio element non initialisÃ©!')
        if (handsFreeModeEnabled) {
          setTimeout(() => voiceInputRef.current?.startRecording(), 1000)
        }
        return
      }

      const audioUrl = URL.createObjectURL(audioBlob)

      // Nettoyer les anciens listeners
      audio.onended = null
      audio.onerror = null

      // Configurer le nouveau src
      audio.src = audioUrl
      audio.volume = 1.0
      audio.preload = 'auto'
      console.log('ğŸµ Audio source mise Ã  jour, volume:', audio.volume)

      // Cleanup function
      let cleanedUp = false
      const cleanup = () => {
        if (!cleanedUp) {
          URL.revokeObjectURL(audioUrl)
          cleanedUp = true
          console.log('ğŸ§¹ Object URL libÃ©rÃ©')
        }
      }

      // Mode mains libres: reprendre Ã©coute aprÃ¨s lecture
      if (handsFreeModeEnabled) {
        console.log('ğŸ™ï¸ Mode mains libres: audio.onended configurÃ©')
        audio.onended = () => {
          console.log('âœ… Audio terminÃ©, redÃ©marrage capture dans 1s')
          cleanup()
          setTimeout(() => {
            voiceInputRef.current?.startRecording()
          }, 1000)
        }

        // DÃ©tection intelligente de fin d'audio (comme dÃ©tection silence sur micro)
        let lastTime = 0
        let stuckCount = 0
        const progressCheckInterval = setInterval(() => {
          if (audio.paused || audio.ended) {
            clearInterval(progressCheckInterval)
            return
          }

          const currentTime = audio.currentTime

          // Si l'audio ne progresse pas
          if (Math.abs(currentTime - lastTime) < 0.1) {
            stuckCount++
            console.log(`â¸ï¸ Audio ne progresse pas (${stuckCount}/4)`)

            // Si bloquÃ© pendant 2 secondes (4 checks Ã— 500ms)
            if (stuckCount >= 4) {
              console.warn('âš ï¸ Audio bloquÃ© - considÃ©rÃ© comme terminÃ©')
              clearInterval(progressCheckInterval)
              audio.pause()
              audio.currentTime = 0
              cleanup()
              voiceInputRef.current?.startRecording()
            }
          } else {
            // L'audio progresse normalement
            stuckCount = 0
            lastTime = currentTime
          }
        }, 500) // Check toutes les 500ms

        // Timeout de sÃ©curitÃ© trÃ¨s long (10 minutes) au cas oÃ¹
        const safetyTimeoutId = setTimeout(() => {
          console.warn('âš ï¸ Timeout sÃ©curitÃ© 10min - arrÃªt forcÃ©')
          clearInterval(progressCheckInterval)
          audio.pause()
          audio.currentTime = 0
          cleanup()
          voiceInputRef.current?.startRecording()
        }, 600000) // 10 minutes

        audio.addEventListener('ended', () => {
          clearInterval(progressCheckInterval)
          clearTimeout(safetyTimeoutId)
        }, { once: true })
      }

      console.log('â–¶ï¸ Tentative lecture audio...')

      // Son de notification avant vocalisation
      playSound('tts-start')

      const playPromise = audio.play()

      if (playPromise !== undefined) {
        playPromise.then(() => {
          console.log('âœ… Audio en lecture - SUCCÃˆS!')
          console.log(`   Duration: ${audio.duration}s`)
          console.log(`   Volume: ${audio.volume}`)
          console.log(`   CurrentTime: ${audio.currentTime}s`)
        }).catch(err => {
          console.error('âŒ ERREUR lecture audio:', err.name, '|', err.message)
          console.error(`   Audio readyState: ${audio.readyState}`)
          console.error(`   Audio networkState: ${audio.networkState}`)
          console.error(`   Audio paused: ${audio.paused}`)
          cleanup()
          // Reprendre capture quand mÃªme si audio Ã©choue
          if (handsFreeModeEnabled) {
            setTimeout(() => {
              voiceInputRef.current?.startRecording()
            }, 1000)
          }
        })
      }
    } catch (error) {
      console.error('âŒ Erreur TTS:', error)
      // Reprendre capture quand mÃªme
      if (handsFreeModeEnabled) {
        setTimeout(() => {
          voiceInputRef.current?.startRecording()
        }, 1000)
      }
    }
  }

  // Fonction pour dÃ©tecter les phrases complÃ¨tes et vocaliser
  const speakSentenceQueue = useRef([]) // Queue de phrases Ã  vocaliser
  const isSpeaking = useRef(false) // Flag pour savoir si on est en train de parler

  // Fonction pour nettoyer le markdown avant TTS
  const cleanMarkdownForTTS = (text) => {
    let cleaned = text

    // Enlever les blocs de code (``` ... ```)
    cleaned = cleaned.replace(/```[\s\S]*?```/g, '')

    // Enlever le code inline mais garder le contenu (`code` -> code)
    cleaned = cleaned.replace(/`(.+?)`/g, '$1')

    // Enlever les emojis
    cleaned = cleaned.replace(/[\u{1F300}-\u{1F9FF}]/gu, '')
    cleaned = cleaned.replace(/[\u{2600}-\u{26FF}]/gu, '')
    cleaned = cleaned.replace(/[\u{2700}-\u{27BF}]/gu, '')

    // Enlever les titres markdown (## ### etc) mais GARDER le texte
    cleaned = cleaned.replace(/^#{1,6}\s+/gm, '')

    // Enlever les ** et __ (bold) mais GARDER le contenu
    cleaned = cleaned.replace(/\*\*(.+?)\*\*/g, '$1')
    cleaned = cleaned.replace(/__(.+?)__/g, '$1')

    // Enlever les * et _ (italic) mais GARDER le contenu
    cleaned = cleaned.replace(/\*(.+?)\*/g, '$1')
    cleaned = cleaned.replace(/_(.+?)_/g, '$1')

    // Enlever les bullets et listes - ajouter une virgule
    cleaned = cleaned.replace(/^[\-\*\+]\s+/gm, ', ')
    cleaned = cleaned.replace(/^\d+\.\s+/gm, ', ')

    // Enlever les liens markdown [text](url) -> text
    cleaned = cleaned.replace(/\[(.+?)\]\(.+?\)/g, '$1')

    // Enlever les chevrons (citations)
    cleaned = cleaned.replace(/^>\s+/gm, '')

    // Enlever les lignes horizontales
    cleaned = cleaned.replace(/^[\-\*_]{3,}$/gm, '')

    // Nettoyer les espaces multiples
    cleaned = cleaned.replace(/\s+/g, ' ')

    // Nettoyer les virgules multiples
    cleaned = cleaned.replace(/,\s*,/g, ',')

    return cleaned.trim()
  }

  const processSpeechQueue = async () => {
    if (isSpeaking.current || speakSentenceQueue.current.length === 0) return

    isSpeaking.current = true
    const sentence = speakSentenceQueue.current.shift()

    // Le texte est DÃ‰JÃ€ nettoyÃ© avant d'entrer dans la queue
    console.log('ğŸ”Š Vocalisation:', sentence)

    try {
      await speakText(sentence)
    } catch (error) {
      console.error('âŒ Erreur TTS sentence:', error)
    }

    isSpeaking.current = false

    // Continuer avec la prochaine phrase
    if (speakSentenceQueue.current.length > 0) {
      setTimeout(processSpeechQueue, 100)
    }
  }

  const sendToClaudeCode = async (userMessage, assistantIndex) => {
    // Mode Claude Code: Stream SSE en temps rÃ©el
    try {
      console.log('ğŸ“¤ Envoi Ã  Claude Code via SSE stream')

      // Envoyer le message
      const response = await fetch(`${config.BACKEND_URL}/claude-input`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: userMessage })
      })

      if (!response.ok) {
        throw new Error('Erreur backend Claude')
      }

      console.log('âœ… Message envoyÃ©, connexion SSE...')

      // Se connecter au stream SSE
      const eventSource = new EventSource(`${config.BACKEND_URL}/claude-stream`)
      let fullText = ''
      let sentenceBuffer = '' // Buffer pour accumuler jusqu'Ã  avoir une phrase complÃ¨te
      let alreadySpoken = new Set() // Track des phrases dÃ©jÃ  vocalisÃ©es pour Ã©viter doublons
      let stabilityTimer = null // Timer pour dÃ©tecter fin de stream
      let hasVocalized = false // Flag pour Ã©viter double vocalisation

      const vocalizeComplete = () => {
        if (hasVocalized) return // Ã‰viter double vocalisation
        hasVocalized = true

        console.log('ğŸ“¡ Stream stabilisÃ© - vocalisation complÃ¨te')
        eventSource.close()

        // Vocaliser le texte COMPLET une fois terminÃ©
        if (fullText.trim() && handsFreeModeEnabled) {
          const cleaned = cleanMarkdownForTTS(fullText)
          console.log('ğŸ”Š Vocalisation complÃ¨te:', cleaned.substring(0, 100) + '...')
          playSound('message-received') // Son de notification
          speakSentenceQueue.current.push(cleaned)
          processSpeechQueue()
        }
      }

      eventSource.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data)
          const delta = data.delta

          if (delta) {
            fullText = data.full

            // Mettre Ã  jour l'affichage en temps rÃ©el
            setMessages(prev => {
              const newMessages = [...prev]
              newMessages[assistantIndex] = {
                ...newMessages[assistantIndex],
                content: fullText
              }
              return newMessages
            })

            // RESET le timer de stabilitÃ© Ã  chaque nouveau delta
            if (stabilityTimer) {
              clearTimeout(stabilityTimer)
            }

            // Si pas de nouveau contenu pendant 2 secondes, on considÃ¨re le stream terminÃ©
            stabilityTimer = setTimeout(() => {
              vocalizeComplete()
            }, 2000) // 2 secondes de silence = stream terminÃ©
          }
        } catch (err) {
          console.error('âŒ Erreur parsing SSE:', err)
        }
      }

      eventSource.onerror = (error) => {
        console.log('ğŸ“¡ SSE error event - vocalisation complÃ¨te')
        if (stabilityTimer) clearTimeout(stabilityTimer)
        vocalizeComplete()
      }

      // Timeout de sÃ©curitÃ© (2 minutes)
      setTimeout(() => {
        if (stabilityTimer) clearTimeout(stabilityTimer)
        eventSource.close()
        console.log('â±ï¸ SSE timeout fermÃ©')
      }, 120000)

    } catch (error) {
      console.error('âŒ Erreur communication Claude Code:', error)
      throw error
    }
  }

  const sendMessageDirect = async (message) => {
    if (!message.trim() || isLoading) return

    const userMessage = message.trim()

    setMessages(prev => [...prev, {
      role: 'user',
      content: userMessage,
      timestamp: new Date().toLocaleTimeString('fr-FR')
    }])

    // ğŸŒ‰ Envoyer la commande vocale via WebSocket Bridge
    wsBridge.sendVoiceCommand(userMessage)

    // Son d'envoi
    playSound('message-sent')

    setIsLoading(true)

    // Router selon le mode sÃ©lectionnÃ©
    if (aiMode === 'claude') {
      try {
        // CrÃ©er immÃ©diatement le message assistant vide
        const assistantIndex = messages.length + 1
        setMessages(prev => [...prev, {
          role: 'assistant',
          content: '',
          timestamp: new Date().toLocaleTimeString('fr-FR')
        }])

        // Lancer le stream SSE qui mettra Ã  jour ce message
        await sendToClaudeCode(userMessage, assistantIndex)

      } catch (error) {
        setMessages(prev => [...prev, {
          role: 'assistant',
          content: `Erreur Claude Code: ${error.message}. VÃ©rifie que le bridge est actif.`,
          timestamp: new Date().toLocaleTimeString('fr-FR')
        }])
      } finally {
        setIsLoading(false)
      }
      return
    }

    // Mode GPT4All (code existant)
    try {
      const response = await fetch(`${config.OLLAMA_URL}/api/chat`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: 'mistral',
          messages: [
            { role: 'system', content: systemPrompt || 'Tu es ARCHON, assistant IA local.' },
            { role: 'user', content: userMessage }
          ],
          stream: true
        })
      })

      const reader = response.body.getReader()
      const decoder = new TextDecoder()
      let assistantMessage = ''
      const assistantIndex = messages.length + 1

      setMessages(prev => [...prev, {
        role: 'assistant',
        content: '',
        timestamp: new Date().toLocaleTimeString('fr-FR')
      }])

      while (true) {
        const { done, value } = await reader.read()
        if (done) break

        const chunk = decoder.decode(value)
        const lines = chunk.split('\n').filter(line => line.trim())

        for (const line of lines) {
          try {
            const json = JSON.parse(line)
            if (json.message?.content) {
              assistantMessage += json.message.content
              setMessages(prev => {
                const newMessages = [...prev]
                newMessages[assistantIndex] = {
                  ...newMessages[assistantIndex],
                  content: assistantMessage
                }
                return newMessages
              })
            }
          } catch (e) {}
        }
      }

      // Mode mains libres: auto-lecture de la rÃ©ponse
      if (handsFreeModeEnabled && assistantMessage.trim()) {
        setTimeout(() => {
          speakText(assistantMessage)
        }, 500)
      }
    } catch (error) {
      setMessages(prev => [...prev, {
        role: 'assistant',
        content: `Erreur: ${error.message}. VÃ©rifie qu'Ollama tourne.`,
        timestamp: new Date().toLocaleTimeString('fr-FR')
      }])
    } finally {
      setIsLoading(false)
    }
  }

  const sendMessage = async () => {
    if (!input.trim() || isLoading) return

    const userMessage = input.trim()
    setInput('')

    sendMessageDirect(userMessage)
  }

  return (
    <div className="app">
      {!isStarted && (
        <div style={{
          position: 'fixed',
          top: 0,
          left: 0,
          right: 0,
          bottom: 0,
          backgroundColor: 'rgba(0, 0, 0, 0.9)',
          display: 'flex',
          flexDirection: 'column',
          alignItems: 'center',
          justifyContent: 'center',
          zIndex: 9999
        }}>
          <h1 style={{ color: '#22c55e', fontSize: '3rem', marginBottom: '2rem' }}>ARCHON V3</h1>
          <p style={{ color: 'white', fontSize: '1.2rem', marginBottom: '3rem' }}>Assistant IA Local avec mode mains libres</p>
          <button
            onClick={async () => {
              // CrÃ©er AudioContext immÃ©diatement
              if (!audioContextRef.current) {
                audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
                console.log('ğŸ›ï¸ AudioContext crÃ©Ã© au dÃ©marrage')
              }

              // Reprendre AudioContext
              if (audioContextRef.current.state === 'suspended') {
                await audioContextRef.current.resume()
              }
              console.log('ğŸ”Š AudioContext state:', audioContextRef.current.state)

              // CrÃ©er Ã©lÃ©ment Audio rÃ©utilisable avec technique "play-then-pause"
              if (!audioElementRef.current) {
                audioElementRef.current = new Audio()
                audioElementRef.current.volume = 1.0
                console.log('ğŸµ Audio element crÃ©Ã© et prÃªt')
              }

              // Technique "play-then-pause": dÃ©bloquer autoplay
              const silentAudio = new Audio('data:audio/wav;base64,UklGRigAAABXQVZFZm10IBIAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA')
              silentAudio.volume = 1.0
              try {
                await silentAudio.play()
                console.log('ğŸ”“ Tentative play silence...')
                silentAudio.pause()
                console.log('âœ… Audio dÃ©bloquÃ© - play-then-pause rÃ©ussi!')

                // DÃ©bloquer aussi l'Ã©lÃ©ment rÃ©utilisable
                audioElementRef.current.src = silentAudio.src
                await audioElementRef.current.play()
                audioElementRef.current.pause()
                audioElementRef.current.src = ''
                console.log('âœ… Audio element principal dÃ©bloquÃ©!')

                setIsStarted(true)
              } catch (err) {
                console.warn('âš ï¸ Autoplay partiellement bloquÃ©:', err.message)
                setIsStarted(true) // Continuer quand mÃªme
              }
            }}
            style={{
              padding: '20px 40px',
              fontSize: '1.5rem',
              backgroundColor: '#22c55e',
              color: 'white',
              border: 'none',
              borderRadius: '12px',
              cursor: 'pointer',
              fontWeight: 'bold',
              boxShadow: '0 4px 20px rgba(34, 197, 94, 0.4)'
            }}
          >
            ğŸš€ DÃ©marrer ARCHON
          </button>
        </div>
      )}
      <header className="header">
        <h1>ARCHON V3</h1>
        <p>Assistant IA Local</p>
        <div style={{ display: 'flex', gap: '10px', marginTop: '10px', flexWrap: 'wrap', justifyContent: 'center' }}>
          <button
            onClick={() => setAiMode('gpt4all')}
            style={{
              padding: '8px 16px',
              backgroundColor: aiMode === 'gpt4all' ? '#f97316' : '#6b7280',
              color: 'white',
              border: 'none',
              borderRadius: '6px',
              cursor: 'pointer',
              fontWeight: 'bold',
              fontSize: '14px'
            }}
          >
            ğŸ¤– Mode GPT4All
          </button>
          <button
            onClick={() => setAiMode('claude')}
            style={{
              padding: '8px 16px',
              backgroundColor: aiMode === 'claude' ? '#3b82f6' : '#6b7280',
              color: 'white',
              border: 'none',
              borderRadius: '6px',
              cursor: 'pointer',
              fontWeight: 'bold',
              fontSize: '14px'
            }}
          >
            ğŸ’» Mode Claude Code
          </button>
          <button
            onClick={() => {
              setHandsFreeModeEnabled(!handsFreeModeEnabled)
              playSound(!handsFreeModeEnabled ? 'recording-start' : 'recording-stop')
            }}
            style={{
              padding: '12px 20px',
              backgroundColor: handsFreeModeEnabled ? '#22c55e' : '#ef4444',
              color: 'white',
              border: handsFreeModeEnabled ? '2px solid #16a34a' : '2px solid #dc2626',
              borderRadius: '8px',
              cursor: 'pointer',
              fontWeight: 'bold',
              fontSize: '15px',
              animation: handsFreeModeEnabled ? 'pulse 2s infinite' : 'none',
              boxShadow: handsFreeModeEnabled ? '0 0 15px rgba(34, 197, 94, 0.5)' : 'none',
              transition: 'all 0.3s ease'
            }}
            title={handsFreeModeEnabled ? 'Cliquez pour PAUSE l\'Ã©coute vocale' : 'Cliquez pour RÃ‰SUMER l\'Ã©coute vocale'}
          >
            {handsFreeModeEnabled ? 'â¸ï¸ PAUSE' : 'â–¶ï¸ RÃ‰SUMER'}
          </button>
          <button
            onClick={saveToMemoryV3}
            disabled={messages.length === 0}
            style={{
              padding: '8px 16px',
              backgroundColor: '#8b5cf6',
              color: 'white',
              border: 'none',
              borderRadius: '6px',
              cursor: messages.length === 0 ? 'not-allowed' : 'pointer',
              fontWeight: 'bold',
              fontSize: '14px',
              opacity: messages.length === 0 ? 0.5 : 1
            }}
          >
            ğŸ§  MÃ©moire V3
          </button>
          <button
            onClick={exportHistory}
            disabled={messages.length === 0}
            style={{
              padding: '8px 16px',
              backgroundColor: '#3b82f6',
              color: 'white',
              border: 'none',
              borderRadius: '6px',
              cursor: messages.length === 0 ? 'not-allowed' : 'pointer',
              fontWeight: 'bold',
              fontSize: '14px',
              opacity: messages.length === 0 ? 0.5 : 1
            }}
          >
            ğŸ’¾ JSON
          </button>
          <button
            onClick={clearHistory}
            disabled={messages.length === 0}
            style={{
              padding: '8px 16px',
              backgroundColor: '#ef4444',
              color: 'white',
              border: 'none',
              borderRadius: '6px',
              cursor: messages.length === 0 ? 'not-allowed' : 'pointer',
              fontWeight: 'bold',
              fontSize: '14px',
              opacity: messages.length === 0 ? 0.5 : 1
            }}
          >
            ğŸ—‘ï¸ Effacer
          </button>
        </div>
      </header>

      <div className="chat-container">
        <div className="messages">
          {messages.filter(msg => msg && msg.role).map((msg, i) => (
            <div key={i} className={`message ${msg.role}`}>
              <div className="message-avatar">{msg.role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–'}</div>
              <div className="message-content">
                <div>{msg.content}</div>
                <div style={{ display: 'flex', alignItems: 'center', gap: '10px', marginTop: '5px' }}>
                  <small>{msg.timestamp}</small>
                  {msg.role === 'assistant' && (
                    <button
                      onClick={() => speakText(msg.content)}
                      style={{
                        background: 'none',
                        border: 'none',
                        cursor: 'pointer',
                        fontSize: '16px',
                        padding: '2px'
                      }}
                      title="Lire Ã  voix haute"
                    >
                      ğŸ”Š
                    </button>
                  )}
                </div>
              </div>
            </div>
          ))}
          {isLoading && <div>RÃ©flexion...</div>}
          <div ref={messagesEndRef} />
        </div>

        <div className="input-area">
          <VoiceInput ref={voiceInputRef} onTranscript={handleVoiceTranscript} playSound={playSound} />
          <textarea
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && !e.shiftKey && (e.preventDefault(), sendMessage())}
            placeholder="Message..."
            disabled={isLoading}
          />
          <button onClick={sendMessage} disabled={!input.trim() || isLoading}>
            Envoyer
          </button>
        </div>
      </div>
    </div>
  )
}

export default App
